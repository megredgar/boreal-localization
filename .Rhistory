return(df)
}
#Read txt files to dataframe using defined function
all_data <- do.call(rbind, lapply(files, read_with_metadata))
unique(all_data$aru_id)
txt_dir <- "C:/Users/AlexE/OneDrive - EC-EC/Localization/hawkears/gsa_jun18_0653_hawkears"
wav_dir <- "C:/Users/AlexE/OneDrive - EC-EC/Localization/recordings/gsa_jun18_recordings/gsa_trim"  # Adjust this if needed
#List .txt files
files <- list.files(path = txt_dir, pattern = "\\.txt$", full.names = TRUE)
#Build function to read files
#ignore blank files
read_with_metadata <- function(file_path) {
if (file.info(file_path)$size == 0) {
message("Skipping empty file: ", file_path)
return(NULL)
}
#read file into a dataframe
df <- read.table(file_path, header = FALSE, stringsAsFactors = FALSE)
#split data into three columns: tag start time (s), tag end time (s) and species id
if (ncol(df) >= 3) {
names(df)[1:3] <- c("tag_start", "tag_end", "species_id")
}
#define data types for the new columns
df$tag_start <- as.numeric(df$tag_start)
df$tag_end <- as.numeric(df$tag_end)
#split species code from the hawkears confidence score
species_split <- do.call(rbind, strsplit(df$species_id, ";")) #separated by semi-colon
df$species  <- species_split[, 1]
df$hawkears <- as.numeric(species_split[, 2])
df$species_id <- NULL #remove original column
#map filepath from filename
fname <- tools::file_path_sans_ext(basename(file_path))
file_name <- sub("_HawkEars$", ".wav", fname)
file_path_wav <- file.path(wav_dir, file_name)
df$file <- file_path_wav
#pull the aru id from the filenames
parts <- strsplit(fname, "_")[[1]]
df$aru_id   <- parts[1]  # station code, e.g. A1
df <- df[, c("file", setdiff(names(df), "file"))]
return(df)
}
#Read txt files to dataframe using defined function
all_data <- do.call(rbind, lapply(files, read_with_metadata))
unique(all_data$aru_id)
rec = all_data %>%
select(file, aru_id)
#check
unique(rec$aru_id)
rtk <- read.csv("rtk_pts.csv")
#bring in rtk coordinates for each aru
rtk <- read.csv("C:/Users/AlexE/OneDrive - EC-EC/Localization/data/gsa_rtk.csv")
#join to file list by aru id
aru_coords <- left_join(x=rtk, y=rec, by = "site_code", multiple = "any")
rec = all_data %>%
select(file, aru_id)
#check
unique(rec$aru_id)
#bring in rtk coordinates for each aru
rtk <- read.csv("C:/Users/AlexE/OneDrive - EC-EC/Localization/data/gsa_rtk.csv")
#join to file list by aru id
aru_coords <- left_join(x=rtk, y=rec, by = "aru_id", multiple = "any")
View(rtk)
rec = all_data %>%
select(file, aru_id)
#check
unique(rec$aru_id)
#bring in rtk coordinates for each aru
rtk <- read.csv("C:/Users/AlexE/OneDrive - EC-EC/Localization/data/gsa_rtk.csv")
#join to file list by aru id
aru_coords <- left_join(x=rtk, y=rec, by = "aru_id", multiple = "any")
View(aru_coords)
rec = all_data %>%
select(file, aru_id)
#check
unique(rec$aru_id)
#bring in rtk coordinates for each aru
rtk <- read.csv("C:/Users/AlexE/OneDrive - EC-EC/Localization/data/gsa_rtk.csv")
#join to file list by aru id
aru_coords <- left_join(x=rtk, y=rec, by = "aru_id", multiple = "any")
#filter to only expected columms: filepath, lat(y), and lon(x)
aru_coords = aru_coords %>%
select(file, x, y)
View(all_data)
View(aru_coords)
#save to csv
write.csv(aru_coords, "aru_coords.csv")
global_max_end <- max(all_data$tag_end, na.rm = TRUE)
#create 3s bins
all_bins <- tibble(
bin_start = seq(0, global_max_end, by = 3)
) %>%
mutate(bin_end = bin_start + 3)
#get all species for all ARUs
aru_sp <- all_data %>%
distinct(aru_id, species_code)
global_max_end <- max(all_data$tag_end, na.rm = TRUE)
#create 3s bins
all_bins <- tibble(
bin_start = seq(0, global_max_end, by = 3)
) %>%
mutate(bin_end = bin_start + 3)
#get all species for all ARUs
aru_sp <- all_data %>%
distinct(aru_id, species)
#combine with time bins
bins_sp <- aru_sp %>%
crossing(all_bins)
#populate species detections
presence_df <- bin_sp %>%
left_join(all_data, by = c("aru_id", "species")) %>% #join tag start_end
filter(!(bin_end <= tag_start | bin_start >= tag_end)) %>% #filter to time bins containing tags
distinct(file, species, bin_start, bin_end) %>% #keep only distinct time bins
mutate(present = 1) #denotes detection of species
global_max_end <- max(all_data$tag_end, na.rm = TRUE)
#create 3s bins
all_bins <- tibble(
bin_start = seq(0, global_max_end, by = 3)
) %>%
mutate(bin_end = bin_start + 3)
#get all species for all ARUs
aru_sp <- all_data %>%
distinct(aru_id, species)
#combine with time bins
bins_sp <- aru_sp %>%
crossing(all_bins)
#populate species detections
presence_df <- bins_sp %>%
left_join(all_data, by = c("aru_id", "species")) %>% #join tag start_end
filter(!(bin_end <= tag_start | bin_start >= tag_end)) %>% #filter to time bins containing tags
distinct(file, species, bin_start, bin_end) %>% #keep only distinct time bins
mutate(present = 1) #denotes detection of species
#tidy up
final_unique <- presence_df %>%
select(file, bin_start, bin_end, species, present) %>%
distinct()
#pivot to wide format
final_wide <- final_unique %>%
pivot_wider(
names_from = species,  #make each species a column
values_from = present, #if present in the ARU/time-bin set as 1
values_fill = 0        #if absent, set 0
) %>%
arrange(file, bin_start) %>% #rearrange and rename to match expected fields
rename(start_time = bin_start,
end_time = bin_end)
View(final_wide)
detections <- final_wide %>%
select(file, start_time, end_time, GRSP, SAVS, VESP, WEME, EAKI)
#save to csv
write.csv(detections, "detections.csv")
detections_grsp <- final_wide %>%
select(file, start_time, end_time, GRSP)
#save to csv
write.csv(detections_grsp, "detections_grsp.csv")
detections_grsp <- final_wide %>%
select(file, start_time, end_time, GRSP)
#save to csv
write.csv(detections_grsp, "C:/Users/AlexE/OneDrive - EC-EC/Localization/data/detections_grsp.csv")
detections <- final_wide %>%
select(file, start_time, end_time, GRSP, VESP, SAVS, WEME, EAKI)
#save to csv
write.csv(detections, "C:/Users/AlexE/OneDrive - EC-EC/Localization/data/detections.csv")
txt_dir <- "C:/Users/AlexE/OneDrive - EC-EC/Localization/hawkears/gsa_jun18_0653_hawkears"
wav_dir <- "C:/Users/AlexE/OneDrive - EC-EC/Localization/recordings/gsa_jun18_recordings/gsa_trim"  # Adjust this if needed
#List .txt files
files <- list.files(path = txt_dir, pattern = "\\.txt$", full.names = TRUE)
#Build function to read files
#ignore blank files
read_with_metadata <- function(file_path) {
if (file.info(file_path)$size == 0) {
message("Skipping empty file: ", file_path)
return(NULL)
}
#read file into a dataframe
df <- read.table(file_path, header = FALSE, stringsAsFactors = FALSE)
#split data into three columns: tag start time (s), tag end time (s) and species id
if (ncol(df) >= 3) {
names(df)[1:3] <- c("tag_start", "tag_end", "species_id")
}
#define data types for the new columns
df$tag_start <- as.numeric(df$tag_start)
df$tag_end <- as.numeric(df$tag_end)
#split species code from the hawkears confidence score
species_split <- do.call(rbind, strsplit(df$species_id, ";")) #separated by semi-colon
df$species  <- species_split[, 1]
df$hawkears <- as.numeric(species_split[, 2])
df$species_id <- NULL #remove original column
#map filepath from filename
fname <- tools::file_path_sans_ext(basename(file_path))
file_name <- sub("_HawkEars$", ".wav", fname)
file_path_wav <- file.path(wav_dir, file_name)
df$file <- file_path_wav
#pull the aru id from the filenames
parts <- strsplit(fname, "_")[[1]]
df$aru_id   <- parts[1]  # station code, e.g. A1
df <- df[, c("file", setdiff(names(df), "file"))]
return(df)
}
#Read txt files to dataframe using defined function
all_data <- do.call(rbind, lapply(files, read_with_metadata))
View(all_data)
wav_dir <- "C:/Users/AlexE/OneDrive - EC-EC/Localization/recordings/gsa_trim"  # Adjust this if needed
all_data <- do.call(rbind, lapply(files, read_with_metadata))
View(all_data)
txt_dir <- "C:/Users/AlexE/OneDrive - EC-EC/Localization/hawkears/gsa_jun18_0653_hawkears"
wav_dir <- "C:/Users/AlexE/OneDrive - EC-EC/Localization/recordings/gsa_trim"  # Adjust this if needed
#List .txt files
files <- list.files(path = txt_dir, pattern = "\\.txt$", full.names = TRUE)
#Build function to read files
#ignore blank files
read_with_metadata <- function(file_path) {
if (file.info(file_path)$size == 0) {
message("Skipping empty file: ", file_path)
return(NULL)
}
#read file into a dataframe
df <- read.table(file_path, header = FALSE, stringsAsFactors = FALSE)
#split data into three columns: tag start time (s), tag end time (s) and species id
if (ncol(df) >= 3) {
names(df)[1:3] <- c("tag_start", "tag_end", "species_id")
}
#define data types for the new columns
df$tag_start <- as.numeric(df$tag_start)
df$tag_end <- as.numeric(df$tag_end)
#split species code from the hawkears confidence score
species_split <- do.call(rbind, strsplit(df$species_id, ";")) #separated by semi-colon
df$species  <- species_split[, 1]
df$hawkears <- as.numeric(species_split[, 2])
df$species_id <- NULL #remove original column
#map filepath from filename
fname <- tools::file_path_sans_ext(basename(file_path))
file_name <- sub("_HawkEars$", ".wav", fname)
file_path_wav <- file.path(wav_dir, file_name)
df$file <- file_path_wav
#pull the aru id from the filenames
parts <- strsplit(fname, "_")[[1]]
df$aru_id   <- parts[1]  # station code, e.g. A1
df <- df[, c("file", setdiff(names(df), "file"))]
return(df)
}
#Read txt files to dataframe using defined function
all_data <- do.call(rbind, lapply(files, read_with_metadata))
View(all_data)
rec = all_data %>%
select(file, aru_id)
library(tidyverse)
library(stringr)
library(tools)
library(dplyr)
library(tidyr)
rec = all_data %>%
select(file, aru_id)
#check
unique(rec$aru_id)
rtk <- read.csv("C:/Users/AlexE/OneDrive - EC-EC/Localization/data/gsa_rtk.csv")
#join to file list by aru id
aru_coords <- left_join(x=rtk, y=rec, by = "aru_id", multiple = "any")
#filter to only expected columms: filepath, lat(y), and lon(x)
aru_coords = aru_coords %>%
select(file, x, y)
View(aru_coords)
#save to csv
write.csv(aru_coords, "aru_coords.csv")
global_max_end <- max(all_data$tag_end, na.rm = TRUE)
#create 3s bins
all_bins <- tibble(
bin_start = seq(0, global_max_end, by = 3)
) %>%
mutate(bin_end = bin_start + 3)
#get all species for all ARUs
aru_sp <- all_data %>%
distinct(aru_id, species)
#combine with time bins
bins_sp <- aru_sp %>%
crossing(all_bins)
#populate species detections
presence_df <- bins_sp %>%
left_join(all_data, by = c("aru_id", "species")) %>% #join tag start_end
filter(!(bin_end <= tag_start | bin_start >= tag_end)) %>% #filter to time bins containing tags
distinct(file, species, bin_start, bin_end) %>% #keep only distinct time bins
mutate(present = 1) #denotes detection of species
#tidy up
final_unique <- presence_df %>%
select(file, bin_start, bin_end, species, present) %>%
distinct()
#pivot to wide format
final_wide <- final_unique %>%
pivot_wider(
names_from = species,  #make each species a column
values_from = present, #if present in the ARU/time-bin set as 1
values_fill = 0        #if absent, set 0
) %>%
arrange(file, bin_start) %>% #rearrange and rename to match expected fields
rename(start_time = bin_start,
end_time = bin_end)
detections_grsp <- final_wide %>%
select(file, start_time, end_time, GRSP)
#save to csv
write.csv(detections_grsp, "C:/Users/AlexE/OneDrive - EC-EC/Localization/data/detections_grsp.csv")
#save to csv
write.csv(aru_coords, "C:/Users/AlexE/OneDrive - EC-EC/Localization/data/aru_coords.csv")
txt_dir <- "C:/Users/AlexE/OneDrive - EC-EC/Localization/hawkears/gsa_grsp_trim"
wav_dir <- "C:/Users/AlexE/OneDrive - EC-EC/Localization/recordings/gsa_grsp_trim"  # Adjust this if needed
#List .txt files
files <- list.files(path = txt_dir, pattern = "\\.txt$", full.names = TRUE)
#Build function to read files
#ignore blank files
read_with_metadata <- function(file_path) {
if (file.info(file_path)$size == 0) {
message("Skipping empty file: ", file_path)
return(NULL)
}
#read file into a dataframe
df <- read.table(file_path, header = FALSE, stringsAsFactors = FALSE)
#split data into three columns: tag start time (s), tag end time (s) and species id
if (ncol(df) >= 3) {
names(df)[1:3] <- c("tag_start", "tag_end", "species_id")
}
#define data types for the new columns
df$tag_start <- as.numeric(df$tag_start)
df$tag_end <- as.numeric(df$tag_end)
#split species code from the hawkears confidence score
species_split <- do.call(rbind, strsplit(df$species_id, ";")) #separated by semi-colon
df$species  <- species_split[, 1]
df$hawkears <- as.numeric(species_split[, 2])
df$species_id <- NULL #remove original column
#map filepath from filename
fname <- tools::file_path_sans_ext(basename(file_path))
file_name <- sub("_HawkEars$", ".wav", fname)
file_path_wav <- file.path(wav_dir, file_name)
df$file <- file_path_wav
#pull the aru id from the filenames
parts <- strsplit(fname, "_")[[1]]
df$aru_id   <- parts[1]  # station code, e.g. A1
df <- df[, c("file", setdiff(names(df), "file"))]
return(df)
}
#Read txt files to dataframe using defined function
all_data <- do.call(rbind, lapply(files, read_with_metadata))
txt_dir <- "C:/Users/AlexE/OneDrive - EC-EC/Localization/hawkears/snas_grsp_trim"
wav_dir <- "C:/Users/AlexE/OneDrive - EC-EC/Localization/recordings/snas_grsp_trim"  # Adjust this if needed
#List .txt files
files <- list.files(path = txt_dir, pattern = "\\.txt$", full.names = TRUE)
#Build function to read files
#ignore blank files
read_with_metadata <- function(file_path) {
if (file.info(file_path)$size == 0) {
message("Skipping empty file: ", file_path)
return(NULL)
}
#read file into a dataframe
df <- read.table(file_path, header = FALSE, stringsAsFactors = FALSE)
#split data into three columns: tag start time (s), tag end time (s) and species id
if (ncol(df) >= 3) {
names(df)[1:3] <- c("tag_start", "tag_end", "species_id")
}
#define data types for the new columns
df$tag_start <- as.numeric(df$tag_start)
df$tag_end <- as.numeric(df$tag_end)
#split species code from the hawkears confidence score
species_split <- do.call(rbind, strsplit(df$species_id, ";")) #separated by semi-colon
df$species  <- species_split[, 1]
df$hawkears <- as.numeric(species_split[, 2])
df$species_id <- NULL #remove original column
#map filepath from filename
fname <- tools::file_path_sans_ext(basename(file_path))
file_name <- sub("_HawkEars$", ".wav", fname)
file_path_wav <- file.path(wav_dir, file_name)
df$file <- file_path_wav
#pull the aru id from the filenames
parts <- strsplit(fname, "_")[[1]]
df$aru_id   <- parts[1]  # station code, e.g. A1
df <- df[, c("file", setdiff(names(df), "file"))]
return(df)
}
#Read txt files to dataframe using defined function
all_data <- do.call(rbind, lapply(files, read_with_metadata))
txt_dir <- "C:/Users/AlexE/OneDrive - EC-EC/Localization/recordings/snas_grsp_trim"
wav_dir <- "C:/Users/AlexE/OneDrive - EC-EC/Localization/recordings/snas_grsp_trim"  # Adjust this if needed
#List .txt files
files <- list.files(path = txt_dir, pattern = "\\.txt$", full.names = TRUE)
#Build function to read files
#ignore blank files
read_with_metadata <- function(file_path) {
if (file.info(file_path)$size == 0) {
message("Skipping empty file: ", file_path)
return(NULL)
}
#read file into a dataframe
df <- read.table(file_path, header = FALSE, stringsAsFactors = FALSE)
#split data into three columns: tag start time (s), tag end time (s) and species id
if (ncol(df) >= 3) {
names(df)[1:3] <- c("tag_start", "tag_end", "species_id")
}
#define data types for the new columns
df$tag_start <- as.numeric(df$tag_start)
df$tag_end <- as.numeric(df$tag_end)
#split species code from the hawkears confidence score
species_split <- do.call(rbind, strsplit(df$species_id, ";")) #separated by semi-colon
df$species  <- species_split[, 1]
df$hawkears <- as.numeric(species_split[, 2])
df$species_id <- NULL #remove original column
#map filepath from filename
fname <- tools::file_path_sans_ext(basename(file_path))
file_name <- sub("_HawkEars$", ".wav", fname)
file_path_wav <- file.path(wav_dir, file_name)
df$file <- file_path_wav
#pull the aru id from the filenames
parts <- strsplit(fname, "_")[[1]]
df$aru_id   <- parts[1]  # station code, e.g. A1
df <- df[, c("file", setdiff(names(df), "file"))]
return(df)
}
#Read txt files to dataframe using defined function
all_data <- do.call(rbind, lapply(files, read_with_metadata))
library(tidyverse)
library(stringr)
library(tools)
library(dplyr)
library(tidyr)
txt_dir <- "C:/Users/AlexE/OneDrive - EC-EC/Localization/recordings/snas_grsp_trim"
wav_dir <- "C:/Users/AlexE/OneDrive - EC-EC/Localization/recordings/snas_grsp_trim"  # Adjust this if needed
#List .txt files
files <- list.files(path = txt_dir, pattern = "\\.txt$", full.names = TRUE)
#Build function to read files
#ignore blank files
read_with_metadata <- function(file_path) {
if (file.info(file_path)$size == 0) {
message("Skipping empty file: ", file_path)
return(NULL)
}
#read file into a dataframe
df <- read.table(file_path, header = FALSE, stringsAsFactors = FALSE)
#split data into three columns: tag start time (s), tag end time (s) and species id
if (ncol(df) >= 3) {
names(df)[1:3] <- c("tag_start", "tag_end", "species_id")
}
#define data types for the new columns
df$tag_start <- as.numeric(df$tag_start)
df$tag_end <- as.numeric(df$tag_end)
#split species code from the hawkears confidence score
species_split <- do.call(rbind, strsplit(df$species_id, ";")) #separated by semi-colon
df$species  <- species_split[, 1]
df$hawkears <- as.numeric(species_split[, 2])
df$species_id <- NULL #remove original column
#map filepath from filename
fname <- tools::file_path_sans_ext(basename(file_path))
file_name <- sub("_HawkEars$", ".wav", fname)
file_path_wav <- file.path(wav_dir, file_name)
df$file <- file_path_wav
#pull the aru id from the filenames
parts <- strsplit(fname, "_")[[1]]
df$aru_id   <- parts[1]  # station code, e.g. A1
df <- df[, c("file", setdiff(names(df), "file"))]
return(df)
}
#Read txt files to dataframe using defined function
all_data <- do.call(rbind, lapply(files, read_with_metadata))
unique(all_data$aru_id)
rec = all_data %>%
select(file, aru_id)
#check
unique(rec$aru_id)
#bring in rtk coordinates for each aru
rtk <- read.csv("C:/Users/AlexE/OneDrive - EC-EC/Localization/data/gsa_rtk.csv")
#join to file list by aru id
aru_coords <- left_join(x=rtk, y=rec, by = "aru_id", multiple = "any")
#filter to only expected columms: filepath, lat(y), and lon(x)
aru_coords = aru_coords %>%
select(file, x, y)
View(all_data)
View(aru_coords)
#save to csv
write.csv(aru_coords, "C:/Users/AlexE/OneDrive - EC-EC/Localization/data/gsa_noB1.csv")
global_max_end <- max(all_data$tag_end, na.rm = TRUE)
#create 3s bins
all_bins <- tibble(
bin_start = seq(0, global_max_end, by = 3)
) %>%
mutate(bin_end = bin_start + 3)
#get all species for all ARUs
aru_sp <- all_data %>%
distinct(aru_id, species)
#combine with time bins
bins_sp <- aru_sp %>%
crossing(all_bins)
#populate species detections
presence_df <- bins_sp %>%
left_join(all_data, by = c("aru_id", "species")) %>% #join tag start_end
filter(!(bin_end <= tag_start | bin_start >= tag_end)) %>% #filter to time bins containing tags
distinct(file, species, bin_start, bin_end) %>% #keep only distinct time bins
mutate(present = 1) #denotes detection of species
#tidy up
final_unique <- presence_df %>%
select(file, bin_start, bin_end, species, present) %>%
distinct()
#pivot to wide format
final_wide <- final_unique %>%
pivot_wider(
names_from = species,  #make each species a column
values_from = present, #if present in the ARU/time-bin set as 1
values_fill = 0        #if absent, set 0
) %>%
arrange(file, bin_start) %>% #rearrange and rename to match expected fields
rename(start_time = bin_start,
end_time = bin_end)
gsa_grsp_follow <- final_wide %>%
select(file, start_time, end_time, GRSP)
#save to csv
write.csv(detections_grsp, "C:/Users/AlexE/OneDrive - EC-EC/Localization/data/gsa_grsp_follow.csv")
#save to csv
write.csv(gsa_grsp_follow, "C:/Users/AlexE/OneDrive - EC-EC/Localization/data/gsa_grsp_follow.csv")
